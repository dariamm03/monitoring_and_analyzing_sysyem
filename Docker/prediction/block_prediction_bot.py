import requests
import json
import os
import re
import time
from datetime import datetime
import hashlib
import traceback
import pyodbc
import numpy as np
from xgboost import Booster
import xgboost as xgb
from pathlib import Path

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
SQLSERVER_CONN = os.getenv("SQLSERVER_CONN")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# –ü—É—Ç—å –∫ settings ‚Äî –ø—Ä—è–º–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
SETTINGS_DIR = os.getenv("SETTINGS_DIR", "/app/settings")

print("[DEBUG] SCRIPT_DIR:", SCRIPT_DIR)
print("[DEBUG] SETTINGS_DIR:", SETTINGS_DIR)
print("[DEBUG] –§–∞–π–ª—ã:", os.listdir(SETTINGS_DIR) if os.path.exists(SETTINGS_DIR) else "‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")



GRAFANA_PLUGIN_PUBLIC = os.path.abspath(
    os.path.join(SCRIPT_DIR, "../Grafana/plugins/grafana-block-alert-panel/public")
)
QUERY_LOG_PATH = "queries.jsonl"
TEXT_LOG_PATH = "logs/queries.log"
ALERT_THRESHOLD = float(os.getenv("ALERT_THRESHOLD", 0.8))
MODEL_PATH = os.getenv("MODEL_PATH", os.path.join(SCRIPT_DIR, "xgb_model.json"))
BLOCK_LOG_PATH = os.path.join(SCRIPT_DIR, "logs", "block_prediction.log")

# === –õ–æ–≥ –¥–ª—è Grafana Loki ===
def log_for_grafana(prob: float, session_id: str, db: str, sql: str):
    try:
        os.makedirs(os.path.dirname(BLOCK_LOG_PATH), exist_ok=True)
        sql_clean = re.sub(r"\s+", " ", sql.strip())
        line = f"[{datetime.now().isoformat()}] session={session_id} db={db} SQL: {sql_clean} Probability: {prob:.3f}"
        with open(BLOCK_LOG_PATH, "a", encoding="utf-8") as f:
            f.write(line + "\n")
        print("[GRAFANA-LOG]", line)
    except Exception as e:
        print(f"[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –ª–æ–≥ –¥–ª—è Grafana: {e}")

# === –§–∏–ª—å—Ç—Ä –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ===
IGNORED_SQL_PATTERNS = [
    r"sys\.dm_exec_",
    r"msrepl_",
    r"sp_ms",
    r"from sys\.dm_exec_requests",
    r"create procedure sys\.sp_msget_repl_commands"
]

def should_ignore_sql(sql: str) -> bool:
    sql = sql.lower()
    return any(re.search(pat, sql) for pat in IGNORED_SQL_PATTERNS)

# === –õ–æ–≥–∏–∫–∞ –º–æ–¥–µ–ª–∏ ===
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {MODEL_PATH}")

model = Booster()
model.load_model(MODEL_PATH)

def extract_features(sql: str, duration: float = 0.0):
    sql = sql.lower()
    temp_tables = re.findall(r"#\w+", sql)
    temp_table_count = len(set(temp_tables))
    complex_join = any(k in sql for k in [" like ", "substring", "charindex", "concat", "trim"])
    return {
        "query_type_encoded": int(0 if "select" in sql else 1 if "update" in sql else 2 if "insert" in sql else 3 if "delete" in sql else 4 if "alter" in sql else 5 if "exec" in sql else 6),
        "has_transaction": int("begin transaction" in sql or "begin tran" in sql),
        "has_join_count": sql.count(" join "),
        "has_subquery": int(sql.count("select") > 1),
        "has_nolock": int("with (nolock)" in sql),
        "has_or_in_where": int(" or " in sql and "where" in sql),
        "uses_temp_table": int("#temp" in sql or "into #" in sql),
        "temp_table_count": temp_table_count,
        "is_ddl": int("alter table" in sql or "drop table" in sql),
        "starts_with_exec": int(sql.strip().startswith("exec")),
        "text_length": len(sql),
        "estimated_rows": min(len(sql) * 10, 100000),
        "complex_join": int(complex_join),
        "query_duration": duration,
        "starts_with_select": int(sql.strip().startswith("select"))
    }

# === –õ–æ–≥–∏–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π ===
def log_query(query: str, session_id: str, db: str = "unknown"):
    os.makedirs(os.path.join(SCRIPT_DIR, "logs"), exist_ok=True)
    record = {
        "timestamp": datetime.now().isoformat(),
        "query_hash": hashlib.md5(query.encode()).hexdigest(),
        "session_id": session_id,
        "database": db,
        "query": query
    }
    with open(os.path.join(SCRIPT_DIR, QUERY_LOG_PATH), "a", encoding="utf-8") as f:
        f.write(json.dumps(record) + "\n")

def already_logged(session_id: str, query: str):
    path = os.path.join(SCRIPT_DIR, QUERY_LOG_PATH)
    if not os.path.exists(path):
        return False
    query_hash = hashlib.md5(query.encode()).hexdigest()
    with open(path, "r", encoding="utf-8") as f:
        for line in reversed(list(f)):
            try:
                entry = json.loads(line)
                if entry["session_id"] == session_id and entry["query_hash"] == query_hash:
                    return True
            except Exception:
                continue
    return False

def log_query_text_to_file(query: str, session_id: str, db: str = "unknown"):
    with open(os.path.join(SCRIPT_DIR, TEXT_LOG_PATH), "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().isoformat()}] session_id={session_id} db={db} sql={query.strip()}\n")

def write_json_log(prob: float, session_id: str, db: str, sql: str):
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "user": session_id,
        "app": db,
        "message": sql.strip(),
        "probability": prob
    }
    path = os.path.join(GRAFANA_PLUGIN_PUBLIC, "logs.json")
    os.makedirs(os.path.dirname(path), exist_ok=True)

    try:
        existing = []
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                existing = json.load(f)
        existing.append(log_entry)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(existing[-100:], f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[ERROR] write_json_log: {e}")

def get_chat_ids():
    """–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ chat_id –∏–∑ —Ñ–∞–π–ª–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ SETTINGS_DIR"""
    chat_ids = set()
    
    if not os.path.exists(SETTINGS_DIR):
        print(f"[WARNING] –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {SETTINGS_DIR}")
        return chat_ids
    
    for file in Path(SETTINGS_DIR).glob("*.json"):
        try:
            with open(file, "r", encoding="utf-8") as f:
                data = json.load(f)
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ chat_id - —ç—Ç–æ –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                chat_id = file.stem
                chat_ids.add(chat_id)
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ {file}: {e}")
    
    print(f"[INFO] –ù–∞–π–¥–µ–Ω–æ chat_ids: {chat_ids}")
    return chat_ids

def send_telegram_alert(message: str, chat_ids=None):
    if not TELEGRAM_TOKEN:
        print("[WARNING] TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É")
        return
    
    if chat_ids is None:
        chat_ids = get_chat_ids()
    
    if not chat_ids:
        print("[WARNING] –ù–µ –Ω–∞–π–¥–µ–Ω–æ chat_ids –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π")
        return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    
    for chat_id in chat_ids:
        try:
            payload = {
                "chat_id": chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            response = requests.post(url, json=payload)
            
            if not response.ok:
                print(f"[ERROR] Telegram response for chat_id {chat_id}: {response.status_code} ‚Äî {response.text}")
            else:
                print(f"[INFO] –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ chat_id {chat_id}")
        except Exception as e:
            print(f"[ERROR] Telegram error for chat_id {chat_id}: {e}")

# === –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ ===
def fetch_active_queries():
    conn = pyodbc.connect(SQLSERVER_CONN)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            r.session_id, 
            DB_NAME(r.database_id) AS db_name, 
            st.text,
            s.program_name,
            r.total_elapsed_time
        FROM sys.dm_exec_requests r
        JOIN sys.dm_exec_sessions s ON r.session_id = s.session_id
        CROSS APPLY sys.dm_exec_sql_text(r.sql_handle) st
        WHERE s.program_name NOT LIKE '%sql-alert-bot%'
    """)
    result = []
    for row in cursor.fetchall():
        sql, session_id, db_name = row.text, str(row.session_id), row.db_name
        elapsed = row.total_elapsed_time or 0
        if sql:
            result.append((sql, session_id, db_name, elapsed / 1000))
    return result

# === –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ===
def check_queries():
    queries = fetch_active_queries()
    print(f"[INFO] –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}")

    for sql, session_id, db, duration in queries:
        if should_ignore_sql(sql):
            continue

        print(f"\n[QUERY] session={session_id} db={db}\n{sql.strip()}")

        if not already_logged(session_id, sql):
            log_query(sql, session_id, db)
            log_query_text_to_file(sql, session_id, db)

        features = extract_features(sql, duration)
        dmat = xgb.DMatrix(np.array([[features[k] for k in features]]), feature_names=list(features))

        try:
            prob = model.predict(dmat)[0]
        except Exception as e:
            print(f"[ERROR] predict: {e}")
            continue

        print(f"[DEBUG] –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:.3f}")
        log_for_grafana(prob, session_id, db, sql)
        write_json_log(prob, session_id, db, sql)

        if prob > ALERT_THRESHOLD:
            msg = (
                "üö® *–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ MSSQL*\n"
                f"*–°–µ—Å—Å–∏—è:* `{session_id}`\n"
                f"*–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:* `{db}`\n"
                f"*–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:* `{prob:.2%}`\n"
                f"*SQL:* `{sql.strip().replace('`', '')[:200]}...`"
            )
            send_telegram_alert(msg)

# === –ó–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    print("[INFO] MSSQL-–±–ª–æ–∫–∏—Ä–æ–≤–æ—á–Ω—ã–π –±–æ—Ç –∑–∞–ø—É—â–µ–Ω.")
    try:
        while True:
            check_queries()
            time.sleep(10)
    except KeyboardInterrupt:
        print("\n[INFO] –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤—Ä—É—á–Ω—É—é.")
    except Exception as e:
        print(f"[ERROR] {e}")
        traceback.print_exc()